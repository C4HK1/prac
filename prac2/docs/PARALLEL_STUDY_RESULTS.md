# Исследование параллельного алгоритма имитации отжига

## Результаты тестирования

### Конфигурация теста
- **Набор данных**: jobs_10000.csv (10,000 работ)
- **Число процессоров (M)**: 10
- **Закон охлаждения**: Logarithmic
- **Начальная температура**: 100.0
- **Параметры**: localStagnationLimit=50, globalStagnationLimit=5

### Измеренные значения

| Nproc (воркеров) | Среднее время (сек) | Средняя стоимость | Мин. стоимость | Ускорение vs Sequential |
|------------------|---------------------|-------------------|----------------|-------------------------|
| Sequential       | 0.036               | 2.53e+08          | 2.52e+08       | 1.0x (базовый)          |
| 1                | 2.0                 | 2.50e+08          | 2.50e+08       | 0.018x (медленнее!)     |
| 2                | 22.5                | 2.33e+08          | 2.33e+08       | 0.0016x (медленнее!)    |
| 4                | ~45 (оценка)        | ~2.30e+08         | ~2.30e+08      | ~0.0008x (медленнее!)   |

## Ответы на вопросы исследования

### 1. При каком Nproc параллельная версия быстрее последовательной?

**Ответ**: На данном наборе данных (10,000 работ) параллельная версия **НЕ быстрее** последовательной ни при каких значениях Nproc.

**Причины**:
- **Overhead межпроцессного взаимодействия**: Каждая глобальная итерация требует сериализации решения, передачи через UNIX сокеты, десериализации
- **Малый размер задачи**: Последовательный алгоритм выполняется за 0.036 секунды — слишком быстро, чтобы параллелизм окупился
- **Множественные глобальные итерации**: При 5 глобальных итерациях и N воркерах происходит 5×N запусков локального алгоритма

### 2. Качество решения vs Скорость

**Наблюдение**: Параллельная версия находит **лучшие решения** (меньшая стоимость):
- Sequential: 2.52e+08
- 1 worker: 2.50e+08 (улучшение ~0.8%)
- 2 workers: 2.33e+08 (улучшение ~7.5%)

**Вывод**: Параллельная версия работает **точнее** (находит лучшее решение), но **не быстрее**.

### 3. Прирост скорости при увеличении Nproc

**Наблюдение**: Увеличение числа воркеров **замедляет** алгоритм:
- 1 → 2 воркера: время увеличилось в 11.25 раз
- 2 → 4 воркера: оценочно удвоится снова

**Причина**: Каждый воркер требует синхронизации и передачи данных. На малых задачах overhead доминирует.

## Когда параллельная версия будет эффективна?

Параллельная версия станет быстрее последовательной при:
1. **Больших наборах данных**: N > 1,000,000 работ, M > 40 процессоров
2. **Длительных локальных вычислениях**: когда каждый воркер работает минуты/часы
3. **Оптимизации параметров**: уменьшение числа глобальных итераций, увеличение локальных

## Рекомендации

### Для демонстрации преимуществ параллелизма:
```bash
# Тест на "тяжёлом" наборе данных
cd АИО/parallel
./build/parallel_app ../sequential/data/jobs_10000000.csv 40 logarithmic 4 1000

# Сравнение с последовательной версией
cd ../sequential
time ./build/sequential_app data/jobs_10000000.csv 40 logarithmic 1000
```

### Для оптимизации:
1. Увеличить `localStagnationLimit` до 200-500
2. Уменьшить `globalStagnationLimit` до 3-5
3. Использовать меньше воркеров (2-4) для начала

## График зависимости (качественный)

```
Время выполнения (сек)
    ^
 25 |                          ●  (4 workers)
    |                   
 20 |              ●  (2 workers)
    |                   
 15 |              
    |                   
 10 |              
    |                   
  5 |    ●  (1 worker)
    |                   
  0 |----●---------------------------------> Nproc
      seq  1    2    3    4    5    6    7    8

Стоимость решения (K2)
    ^
2.53e8|●  (sequential)
    |                   
2.50e8|    ●  (1 worker)
    |                   
2.40e8|              
    |                   
2.33e8|              ●  (2 workers)
    |                          
2.30e8|                          ○  (4 workers, оценка)
    |                   
    +-----------------------------------------> Nproc
```

## Выводы

1. **Параллельная версия медленнее** на малых задачах (10K работ) из-за overhead
2. **Параллельная версия точнее** — находит лучшие решения за счёт исследования большего пространства
3. **Увеличение Nproc** на малых задачах **замедляет** алгоритм
4. **Для ускорения** нужны: большие данные (1M+ работ), оптимизация параметров, меньше глобальных итераций

